const Typesense = require('typesense')
const fs = require('fs')
const path = require('path')

const typesenseConfig = {
  nodes: [
    {
      host: process.env.TYPESENSE_HOST || 'localhost',
      port: parseInt(process.env.TYPESENSE_PORT || '8108'),
      protocol: process.env.TYPESENSE_PROTOCOL || 'http',
    },
  ],
  apiKey: process.env.TYPESENSE_API_KEY || 'xyz',
  connectionTimeoutSeconds: 10,
}

const productSchema = {
  name: 'products',
  fields: [
    { name: 'id', type: 'string' },
    { name: 'name', type: 'string' },
    { name: 'description', type: 'string' },
    { name: 'price', type: 'float' },
    { name: 'originalPrice', type: 'float' },
    { name: 'discount', type: 'int32' },
    { name: 'category', type: 'string', facet: true },
    { name: 'image', type: 'string' },
    { name: 'rating', type: 'float' },
    { name: 'reviews', type: 'int32' },
    { name: 'stock', type: 'int32' },
    { name: 'tags', type: 'string[]', facet: true },
    { name: 'brand', type: 'string', facet: true },
    { name: 'created_at', type: 'int64' },
  ],
  default_sorting_field: 'rating',
}

async function initializeLargeDataset() {
  try {
    const client = new Typesense.Client(typesenseConfig)

    console.log('üîç Conectando a Typesense...')

    try {
      await client.collections('products').retrieve()
      console.log('‚úÖ La colecci√≥n "products" ya existe')
    } catch (error) {
      console.log('üìù Creando colecci√≥n "products"...')
      await client.collections().create(productSchema)
      console.log('‚úÖ Colecci√≥n "products" creada exitosamente')
    }

    console.log('üì¶ Listo para importar datos...')
    console.log('üí° Usa este script con tu dataset de 15GB')
    console.log('üìä Dashboard: http://localhost:8108/dashboard')

  } catch (error) {
    console.error('‚ùå Error inicializando Typesense:', error.message)
    process.exit(1)
  }
}

async function importDataInBatches(client, data, batchSize = 1000) {
  console.log(`üì¶ Importando ${data.length} productos en lotes de ${batchSize}...`)
  
  const batches = []
  for (let i = 0; i < data.length; i += batchSize) {
    batches.push(data.slice(i, i + batchSize))
  }

  let imported = 0
  for (let i = 0; i < batches.length; i++) {
    const batch = batches[i]
    try {
      const importResults = await client.collections('products').documents().import(batch)
      
      const successCount = importResults.filter(result => !result.error).length
      imported += successCount
      
      console.log(`‚úÖ Lote ${i + 1}/${batches.length}: ${successCount}/${batch.length} productos importados`)
      console.log(`üìä Progreso: ${imported}/${data.length} (${Math.round((imported/data.length)*100)}%)`)
      
      await new Promise(resolve => setTimeout(resolve, 100))
      
    } catch (error) {
      console.error(`‚ùå Error en lote ${i + 1}:`, error.message)
    }
  }
  
  console.log(`üéâ Importaci√≥n completada: ${imported} productos importados`)
}

async function readDataFromFile(filePath) {
  console.log(`üìñ Leyendo datos desde: ${filePath}`)
  
  if (!fs.existsSync(filePath)) {
    throw new Error(`Archivo no encontrado: ${filePath}`)
  }
  
  const fileContent = fs.readFileSync(filePath, 'utf8')
  const lines = fileContent.split('\n').filter(line => line.trim())
  
  console.log(`üìä Encontradas ${lines.length} l√≠neas de datos`)
  
  const products = []
  for (let i = 0; i < lines.length; i++) {
    try {
      const product = JSON.parse(lines[i])
      products.push(product)
    } catch (error) {
      console.warn(`‚ö†Ô∏è  Error parseando l√≠nea ${i + 1}:`, error.message)
    }
  }
  
  return products
}

if (require.main === module) {
  const args = process.argv.slice(2)
  
  if (args.length === 0) {
    console.log('üöÄ Inicializando Typesense para dataset grande...')
    initializeLargeDataset()
  } else if (args[0] === 'import' && args[1]) {
    console.log('üì¶ Importando dataset...')
    const client = new Typesense.Client(typesenseConfig)
    readDataFromFile(args[1])
      .then(data => importDataInBatches(client, data))
      .catch(error => {
        console.error('‚ùå Error importando datos:', error.message)
        process.exit(1)
      })
  } else {
    console.log('Uso:')
    console.log('  node scripts/seed-large-dataset.js                    # Inicializar colecci√≥n')
    console.log('  node scripts/seed-large-dataset.js import <archivo>   # Importar datos')
  }
}

module.exports = { initializeLargeDataset, importDataInBatches, readDataFromFile } 